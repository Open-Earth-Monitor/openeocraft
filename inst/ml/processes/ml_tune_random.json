{
  "id": "ml_tune_random",
  "summary": "Random search hyperparameter tuning",
  "description": "Performs random search over hyperparameter distributions to find optimal model settings. Unlike grid search, random search samples a fixed number of parameter combinations from specified distributions, which can be more efficient for high-dimensional parameter spaces.",
  "categories": [
    "machine learning",
    "model selection"
  ],
  "experimental": true,
  "parameters": [
    {
      "name": "model",
      "description": "An untrained machine learning model object that will be trained and evaluated for each sampled hyperparameter combination.",
      "schema": {
        "type": "object",
        "subtype": "ml-model"
      }
    },
    {
      "name": "training_data",
      "description": "Training samples. Can be provided as a URL to a data file, a local file path, or an inline data object depending on the backend implementation.",
      "schema": [
        {
          "type": "string",
          "subtype": "uri"
        },
        {
          "type": "object"
        }
      ]
    },
    {
      "name": "parameters",
      "description": "Hyperparameter distributions defining the search space. Each key is a hyperparameter name. Values can be arrays (uniform sampling), or objects specifying distributions with 'type' ('uniform', 'log_uniform', 'int_uniform', 'choice') and parameters ('min', 'max', 'values').",
      "schema": {
        "type": "object",
        "additionalProperties": {
          "anyOf": [
            {
              "type": "array",
              "description": "List of discrete values to sample from uniformly.",
              "items": {}
            },
            {
              "type": "object",
              "description": "Distribution specification.",
              "properties": {
                "type": {
                  "type": "string",
                  "enum": [
                    "uniform",
                    "log_uniform",
                    "int_uniform",
                    "choice"
                  ]
                },
                "min": {
                  "type": "number"
                },
                "max": {
                  "type": "number"
                },
                "values": {
                  "type": "array"
                }
              }
            }
          ]
        }
      }
    },
    {
      "name": "n_iter",
      "description": "Number of random parameter combinations to sample and evaluate.",
      "optional": true,
      "default": 10,
      "schema": {
        "type": "integer",
        "minimum": 1
      }
    },
    {
      "name": "target",
      "description": "Name of the target/label column in the training data.",
      "optional": true,
      "default": "label",
      "schema": {
        "type": "string"
      }
    },
    {
      "name": "scoring",
      "description": "Metric used to evaluate and compare model performance. Common metrics include 'accuracy', 'kappa', 'f1', 'precision', 'recall', 'auc'.",
      "optional": true,
      "default": "accuracy",
      "schema": {
        "type": "string"
      }
    },
    {
      "name": "cv",
      "description": "Number of cross-validation folds. If 0 or 1, uses a single train/validation split instead of cross-validation.",
      "optional": true,
      "default": 5,
      "schema": {
        "type": "integer",
        "minimum": 0
      }
    },
    {
      "name": "validation_split",
      "description": "Fraction of training data used for validation when cv <= 1. Ignored when using cross-validation.",
      "optional": true,
      "default": 0.2,
      "schema": {
        "type": "number",
        "minimum": 0,
        "exclusiveMaximum": 1
      }
    },
    {
      "name": "seed",
      "description": "Random seed for reproducibility of parameter sampling, data splits, and model training.",
      "optional": true,
      "default": null,
      "schema": {
        "type": [
          "integer",
          "null"
        ]
      }
    }
  ],
  "returns": {
    "description": "Tuning results including the best hyperparameters and performance metrics for all evaluated combinations.",
    "schema": {
      "type": "object",
      "subtype": "ml-tuning-result",
      "properties": {
        "best_params": {
          "type": "object",
          "description": "The hyperparameter combination that achieved the best score."
        },
        "best_score": {
          "type": "number",
          "description": "The best score achieved."
        },
        "results": {
          "type": "array",
          "description": "All evaluated parameter combinations with their scores.",
          "items": {
            "type": "object"
          }
        }
      }
    }
  },
  "links": [
    {
      "href": "https://scikit-learn.org/stable/modules/grid_search.html#randomized-parameter-optimization",
      "title": "Scikit-learn Random Search Documentation",
      "type": "text/html",
      "rel": "about"
    },
    {
      "href": "https://www.jmlr.org/papers/v13/bergstra12a.html",
      "title": "Bergstra & Bengio (2012) - Random Search for Hyper-Parameter Optimization",
      "type": "text/html",
      "rel": "about"
    }
  ]
}
